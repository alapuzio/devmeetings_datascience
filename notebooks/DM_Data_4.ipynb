{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DM_Data_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sleter/devmeetings_datascience/blob/master/notebooks/DM_Data_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYPNdhdZMbDp",
        "colab_type": "text"
      },
      "source": [
        "# Tworzenie własnego potoku transformującego dane"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rms5ZKwvMf0p",
        "colab_type": "text"
      },
      "source": [
        "### Tworzenie niestandardowych transformatorów"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL_cYOZhONnd",
        "colab_type": "text"
      },
      "source": [
        "Jak zauważyliśmy biblioteka Scikit-Learn posiada wiele przydatnych funkcji tranformujących jak np. SimpleImputer czy LabelEncoder. Czasami jednak jest potrzeba zdefiniowania własnej funkcji transformującej.\n",
        "\n",
        "Dzięki mechanizmowi dziedziczenia w bibliotece Scikit-Learn, żeby dodać własny tranformator wystarczy stworzyć klasę i zaimportować 3 metody: *fit*, *transform* oraz *fit_transform*.\n",
        "\n",
        "Metoda *fit_transform* jest połączeniem *fit* i *transform* i nie trzeba jej implementować przy dziedziczeniu po klasie TransformerMixer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Bg88tTX_UQ",
        "colab_type": "code",
        "outputId": "8797d5b0-c3a6-45ec-f4b8-5c7f996b005d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = {\n",
        "    'name':['Tom', 'Nick', 'Tom', 'Jack'],\n",
        "    'age':[20, 21, 19, 18],\n",
        "    'value':[3, 5, 2, 11]}\n",
        "    \n",
        "df_ = pd.DataFrame(data)\n",
        "\n",
        "df_test = df_.copy()\n",
        "df_test['new_value'] = df_['age']*df_['value']\n",
        "print(df_test.head())\n",
        "\n",
        "class NewTransformer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, multiple_by_3 = True, age_index = 1, value_index = 2):\n",
        "    self.multiple_by_3 = multiple_by_3\n",
        "    self.age_index = age_index\n",
        "    self.value_index = value_index\n",
        "  \n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  \n",
        "  def transform(self, X, y = None):\n",
        "    new_value = X[:, self.age_index]*X[:, self.value_index]\n",
        "    if self.multiple_by_3:\n",
        "      new_value = new_value*3\n",
        "    return np.c_[X, new_value]\n",
        "\n",
        "nt = NewTransformer(multiple_by_3=False)\n",
        "print(nt.fit_transform(df_.values))\n",
        "\n",
        "nt = NewTransformer()\n",
        "print(nt.fit_transform(df_.values))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   name  age  value  new_value\n",
            "0   Tom   20      3         60\n",
            "1  Nick   21      5        105\n",
            "2   Tom   19      2         38\n",
            "3  Jack   18     11        198\n",
            "[['Tom' 20 3 60]\n",
            " ['Nick' 21 5 105]\n",
            " ['Tom' 19 2 38]\n",
            " ['Jack' 18 11 198]]\n",
            "[['Tom' 20 3 180]\n",
            " ['Nick' 21 5 315]\n",
            " ['Tom' 19 2 114]\n",
            " ['Jack' 18 11 594]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTNUqlsANZno",
        "colab_type": "text"
      },
      "source": [
        "### Potoki transformujące"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5mRgEPoaY3U",
        "colab_type": "text"
      },
      "source": [
        "Poznaliśmy juz wiele różnych operacji na danych i transformatów.\n",
        "\n",
        "Trzeba jednak pamiętać ciągle w jakiej kolejności je uruchamiać nie pomijając przy tym jakiejś operacji. Tutaj z pomocą przychodza potoki transformujące pozwalające ustalać kolejkę wykonywanych transformacji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-u5Z7jShtza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, attributes_names):\n",
        "    self.attributes_names = attributes_names\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X):\n",
        "    return X[self.attributes_names].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTwK0ObwNfTz",
        "colab_type": "code",
        "outputId": "44b6da93-5109-4fd7-dfc7-4ff7133b0c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "num_columns = list(df_.columns)\n",
        "num_columns.remove(\"name\")\n",
        "cat_columns = [\"name\"]\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "  ('df_selector', DataFrameSelector(cat_columns)),\n",
        "  ('label_encoder', OneHotEncoder(sparse=False)),\n",
        "])\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "  ('df_selector', DataFrameSelector(num_columns)),\n",
        "  ('imputer', SimpleImputer()),\n",
        "  ('new_transformer', NewTransformer(age_index = 0, value_index = 1)),\n",
        "  ('standard_scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "full_pipeline = FeatureUnion(transformer_list=[\n",
        "  ('cat_pipeline', cat_pipeline),\n",
        "  ('num_pipeline', num_pipeline)\n",
        "])\n",
        "\n",
        "print(\"Before: \")\n",
        "print(df_)\n",
        "final_df_ = full_pipeline.fit_transform(df_)\n",
        "print(\"\\nAfter: \")\n",
        "print(final_df_)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before: \n",
            "   name  age  value\n",
            "0   Tom   20      3\n",
            "1  Nick   21      5\n",
            "2   Tom   19      2\n",
            "3  Jack   18     11\n",
            "\n",
            "After: \n",
            "[[ 0.          0.          1.          0.4472136  -0.64450339 -0.65569162]\n",
            " [ 0.          1.          0.          1.34164079 -0.07161149  0.07737976]\n",
            " [ 0.          0.          1.         -0.4472136  -0.93094934 -1.01408207]\n",
            " [ 1.          0.          0.         -1.34164079  1.64706421  1.59239393]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCHSMg9tSGED",
        "colab_type": "text"
      },
      "source": [
        "### Zadania"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gNiXnoxSJj6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   Stwórz własny transformator dla wybranych transformacji dla zbioru danych housing.csv napisanych w notebooku 2 w punkcie \"Zadania\" w podpunkcie 5.\n",
        "2.   Stwórz własny potok transformujący dla zbioru danych housing.csv zawierający osobne operacje dla kolumn kategorycznych i numerycznych.\n",
        "* **Dla kategorycznych** mogą to być operacje wybrania odpowiedniego podzbioru atrybutów kategorycznych i zastąpienia ich macierzą rzadką.\n",
        "* **Dla numerycznych** mogą to być operacje wybrania odpowiedniego podzbioru atrybutów numerycznych, zastąpienie nieznanych wartości średnią, użycie transformatora z zadania wyżej i przeskalowanie wszystkich wartości."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVlKhyXTSJCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WRITE YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}